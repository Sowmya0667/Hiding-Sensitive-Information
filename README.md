# ğŸ” Hiding Sensitive Information from Images and Documents
This project implements a six-stage pipeline to detect and hide personally identifiable information (PII) from real-world images of ID cards and other documents, captured under diverse conditions (different angles, backgrounds, and lighting). It combines computer vision, OCR, and large language models to achieve high accuracy in PII detection and masking. A Streamlit app is included for user-friendly interaction with the pipeline.

---

## ğŸš€ Pipeline Overview

### âœ… Stage 1: Data Collection

- Collected real-world document images from Google and various websites.
- Images vary in background, orientation, and lighting conditions.

### ğŸ§­ Stage 2: ID Card Detection and Cropping

- Annotated images using LabelStudio to create bounding boxes for ID cards.
- Trained a YOLOv8 model on the annotated dataset.
- Detected and cropped ID cards from full document images using predicted bounding boxes.

### ğŸ”„ Stage 3: Image Alignment (Deskewing)

- Used Aspose OCR to calculate the skew angle of cropped images.
- Applied OpenCV to deskew (rotate) images for proper alignment.
- ğŸ“ˆ Result: Well-aligned ID cards optimized for accurate text extraction.

### ğŸ“ Stage 4: OCR Text Extraction

- Utilized PaddleOCR to extract text and obtain layout information (text + coordinates).
- Provides input for LLM-based PII identification.

### ğŸ” Stage 5: PII Extraction with LLM

- Employed Gemini 1.5 Flash LLM to detect PII (e.g., name, DOB, ID number).
- Used coordinates from PaddleOCR, as the LLM cannot extract coordinates directly.
- Enhanced noisy OCR text using the LLM for improved PII detection accuracy.

### ğŸ›¡ï¸ Stage 6: Sensitive Information Masking

- Used OpenCV to draw masks over detected PII coordinates.
- âœ… Final output: Images with sensitive information successfully redacted.

---

## ğŸ“Š Evaluation

Manually corrected PII labels on a test set for validation.


- **âœ… Accuracy**: 91%  
- **ğŸ¯ Precision**: 95%  
- **ğŸ” Recall**: 95%


## ğŸ’» Tech Stack

- ğŸ§  **YOLOv8** â€“ ID card detection  
- ğŸ–Šï¸ **LabelStudio** â€“ Manual annotation of bounding boxes  
- ğŸ§¾ **Aspose OCR + OpenCV** â€“ Image alignment and deskewing  
- ğŸ” **PaddleOCR** â€“ Text extraction and layout analysis  
- ğŸ§  **Gemini 1.5 Flash** â€“ PII detection  
- ğŸ“± **Streamlit** â€“ User interface for the pipeline  
- ğŸ **Python** â€“ Core implementation  
- ğŸ““ **Jupyter Notebooks** â€“ Prototyping and evaluation  


## ğŸ“‹ Prerequisites

- Python 3.8+
- Git
- A compatible environment for GPU acceleration (optional, for YOLOv8 inference)

## ğŸ› ï¸ Setup Instructions

### ğŸ”„ Clone the Repository:

```bash
git clone https://github.com/your-username/sensitive-info-hiding.git
cd sensitive-info-hiding
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

## ğŸ“¥ Download Models:

- Download the trained YOLOv8 model (yolov8_id_card.pt) and place it in the models/ directory.
- Note: Due to file size, the model is not included in the repository. Contact the repository owner or train your own model using the provided scripts.


Prepare Data:

- Place raw images in data/raw/.
- Annotations (if available) should be in data/annotations/ in LabelStudio format.
- âš ï¸ Note: Sensitive data is not included in this repository. Users must provide their own dataset.

## ğŸ§ª Usage

### â–¶ï¸ Running the Pipeline
Execute the pipeline scripts in sequence:

```bash
python scripts/detect_id_card.py
python scripts/crop_images.py
python scripts/deskew_images.py
python scripts/extract_text.py
python scripts/detect_pii.py
python scripts/mask_pii.py
```

## Running the Streamlit App
- Launch the Streamlit app to interact with the pipeline:
```bash
streamlit run app/app.py
```

The app provides a user-friendly interface to upload images, process them through the pipeline, and view masked outputs.


## ğŸ“ Notes

**Data Privacy**: Do not upload sensitive images or data to GitHub. The data/ directory is a placeholder; users must source their own datasets.
**Model Training**: To train your own YOLOv8 model, use the annotations in data/annotations/ and follow the instructions in scripts/detect_id_card.py.
**Docker Deployment**: The Docker setup is in progress and will be added in a future update.

## ğŸ¤ Contributing
Contributions are welcome! Please follow these steps:
1.Fork the repository.
2.Create a new branch (git checkout -b feature/your-feature).
3.Commit changes (git commit -m "Add your feature").
4.Push to the branch (git push origin feature/your-feature).
5.Open a pull request.

ğŸ“¬ Contact
For questions or support, please open an issue on GitHub or contact suryavenkata.mds2024@cmi.ac.in
