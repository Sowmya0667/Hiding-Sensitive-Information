# ğŸ” Hiding Sensitive Information from Images and Documents
This project implements a six-stage pipeline to detect and hide personally identifiable information (PII) from real-world images of ID cards and other documents, captured under diverse conditions (different angles, backgrounds, and lighting). It combines computer vision, OCR, and large language models to achieve high accuracy in PII detection and masking. A Streamlit app is included for user-friendly interaction with the pipeline.

---

## ğŸš€ Pipeline Overview

### âœ… Stage 1: Data Collection

- Collected real-world document images from Google and various websites.
- Images vary in background, orientation, and lighting conditions.

### ğŸ§­ Stage 2: ID Card Detection and Cropping

- Annotated images using LabelStudio to create bounding boxes for ID cards.
- Trained a YOLOv8 model on the annotated dataset.
- Detected and cropped ID cards from full document images using predicted bounding boxes.

### ğŸ”„ Stage 3: Image Alignment (Deskewing)

- Used Aspose OCR to calculate the skew angle of cropped images.
- Applied OpenCV to deskew (rotate) images for proper alignment.
- ğŸ“ˆ Result: Well-aligned ID cards optimized for accurate text extraction.

### ğŸ“ Stage 4: OCR Text Extraction

- Utilized PaddleOCR to extract text and obtain layout information (text + coordinates).
- Provides input for LLM-based PII identification.

### ğŸ” Stage 5: PII Extraction with LLM

- Employed Gemini 1.5 Flash LLM to detect PII (e.g., name, DOB, ID number).
- Used coordinates from PaddleOCR, as the LLM cannot extract coordinates directly.
- Enhanced noisy OCR text using the LLM for improved PII detection accuracy.

### ğŸ›¡ï¸ Stage 6: Sensitive Information Masking

- Used OpenCV to draw masks over detected PII coordinates.
- âœ… Final output: Images with sensitive information successfully redacted.

---

## ğŸ“Š Evaluation

- Evaluated on a test set with manually corrected PII labels (ground truth created by human annotators).
- **Accuracy**: 91%  
- **Precision**: 95%  
- **Recall**: 95%  
- Metrics reflect the performance of the entire pipeline, from ID card detection to PII masking.

---


## ğŸ’» Tools Used

- ğŸ§  **YOLOv8** â€“ ID card detection  
- ğŸ–Šï¸ **LabelStudio** â€“ Manual annotation of bounding boxes  
- ğŸ§¾ **Aspose OCR + OpenCV** â€“ Image alignment and deskewing  
- ğŸ” **PaddleOCR** â€“ Text extraction and layout analysis  
- ğŸ§  **Gemini 1.5 Flash** â€“ PII detection
- ğŸ““ **Pillow**: PII masking 
- ğŸ“± **Streamlit** â€“ User interface for the pipeline  
- ğŸ **Python** â€“ Core implementation  



## ğŸ“ Folder Structure

```markdown
Hiding-Sensitive-Information/
â”œâ”€â”€ data/                  # Data configuration and annotations (no images included)
â”‚   â”œâ”€â”€ annotations/       # LabelStudio annotations for training
â”‚   â”œâ”€â”€ data.yaml          # YOLOv8 data configuration file
â”‚   â””â”€â”€ processed/         # Temporary pipeline outputs (excluded via .gitignore)
â”‚       â”œâ”€â”€ cropped/       # Cropped ID card images
â”‚       â”œâ”€â”€ aligned/       # Deskewed images
â”‚       â””â”€â”€ masked/        # Masked images
â”œâ”€â”€ models/                # Trained models
â”‚   â””â”€â”€ README.md          # YOLOv8 model weights
â”œâ”€â”€ scripts/               # Core pipeline scripts
â”‚   â”œâ”€â”€ train_yolov8.py    # Train YOLOv8 model
â”‚   â”œâ”€â”€ predict_yolov8.py  # Predict ID card bounding boxes
â”‚   â”œâ”€â”€ crop_images.py     # Crop ID cards
â”‚   â”œâ”€â”€ deskew_images.py   # Deskew images
â”‚   â”œâ”€â”€ extract_text.py    # PaddleOCR text extraction
â”‚   â”œâ”€â”€ detect_pii.py      # PII detection with Gemini LLM
â”‚   â”œâ”€â”€ mask_pii.py        # Mask PII with Pillow
â”‚   â””â”€â”€ evaluate.py        # Evaluate accuracy, precision, recall
â”œâ”€â”€ app/                   # Streamlit app
â”‚   â”œâ”€â”€ app.py             # Streamlit app code
â”œâ”€â”€ presentation/          # Project presentation file
â”‚   â””â”€â”€ hiding_sensitive_information_presentation.pdf   
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project overview and instructions
â”œâ”€â”€ LICENSE                # Project license
â””â”€â”€ .gitignore             # Git ignore rules
```

---
## ğŸ“‹ Prerequisites

- Python 3.8+
- Git
- A compatible environment for GPU acceleration (optional, for YOLOv8 training and inference)
- API access for Gemini 1.5 Flash (requires configuration)
- PaddleOCR and Aspose OCR dependencies (see requirements.txt)
- Additional dependencies for evaluation: fuzzywuzzy, numpy, python-Levenshtein (optional, for faster fuzzy matching)
---

## ğŸ› ï¸ Setup Instructions

### ğŸ”„ Clone the Repository:

```bash
git clone https://github.com/Sowmya0667/Hiding-Sensitive-Information.git
cd Hiding-Sensitive-Information
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

## ğŸ“¥ Download Models:

- Download the trained YOLOv8 model (yolov8_id_card.pt) and place it in the models/ directory.
- Note: Due to file size, the model is not included in the repository. Contact the repository owner or train your own model using the provided scripts.


## Prepare Data

- Place raw images in data/raw/ or test images in data/test/.
- Place the YOLOv8 data configuration file (data.yaml) in data/.
- Annotations should be in data/annotations/ in LabelStudio format.
- âš ï¸ **Warning**: Sensitive data is not included in this repository. Users must provide their own dataset. Ensure sensitive files are excluded from version control using .gitignore.

## ğŸ§ª Usage

### â–¶ï¸ Running the Pipeline
Execute the pipeline scripts in sequence:

```bash
python scripts/train_yolov8.py --data_path data/data.yaml
python scripts/predict_yolov8.py --model_path models/yolov8_id_card.pt --source data/test --output_dir data/predictions
python scripts/crop_images.py --image_folder data/test --label_folder data/predictions/predict_train/labels --crop_folder data/processed/cropped
python scripts/deskew_images.py --input_folder data/processed/cropped --output_folder data/processed/aligned
python scripts/extract_text.py --input_folder data/processed/aligned --output_image_folder data/processed/paddle_result/images --output_json_folder data/processed/paddle_result/annotations
python scripts/detect_pii.py --json_folder data/processed/paddle_result/annotations --image_folder data/processed/aligned --output_folder data/processed/pii
python scripts/mask_pii.py --json_folder data/processed/pii --image_folder data/processed/aligned --output_folder data/processed/masked
```

## Running the Streamlit App
- Launch the Streamlit app to upload images, process them through the pipeline, and view masked outputs:
```bash
streamlit run app/app.py
```

The app provides a user-friendly interface to upload images, process them through the pipeline, and view masked outputs.


## ğŸ“ Notes

- **Data Privacy**: Do not upload sensitive images or data to GitHub. The data/ directory is a placeholder; users must source their own datasets.
- **Model Training**: Ensure data.yaml points to your dataset in data/annotations/ and data/raw/. Follow instructions in scripts/train_yolov8.py.
- **Docker Deployment**: The Docker setup is in progress and will be added in a future update.

## ğŸ¤ Contributing
Contributions are welcome! Please follow these steps:
- 1.Fork the repository.
- 2.Create a new branch (git checkout -b feature/your-feature).
- 3.Commit changes (git commit -m "Add your feature").
- 4.Push to the branch (git push origin feature/your-feature).
- 5.Open a pull request.

ğŸ“¬ Contact
For questions or support, please open an issue on GitHub or contact suryavenkata.mds2024@cmi.ac.in
